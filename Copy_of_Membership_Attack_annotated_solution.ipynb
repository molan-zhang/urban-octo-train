{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Membership Attack - annotated solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/molan-zhang/urban-octo-train/blob/master/Copy_of_Membership_Attack_annotated_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvK6LaVhrfZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# required imports\n",
        "import sys \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O05dkTKAsEh-",
        "colab_type": "code",
        "outputId": "28360c75-63cb-4440-a97e-4813c68ef021",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# mount the google drive to download the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "project_path = 'content/drive/My Drive/Colab Notebooks/Cybersecurity/NN Attacks/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEW1mLverl7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create transforms to load the images, nothing much is needed here. \n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjsFJTFwr1wV",
        "colab_type": "code",
        "outputId": "94df546b-de76-413e-9c36-41f709b18226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# download CIFAR 10 training set\n",
        "trainset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "# load the trainning set\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "# download the test data\n",
        "testset = torchvision.datasets.CIFAR10(root=project_path+'/data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "# load the test data\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# check those manually on the dataset site: https://www.cs.toronto.edu/~kriz/cifar.html \n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itY7G_y3tDnC",
        "colab_type": "code",
        "outputId": "f5dd8659-99c7-4d03-f789-4b08b5fa3b0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# helper function to unnormalize and plot image \n",
        "def imshow(img):\n",
        "    img = np.array(img)\n",
        "    img = img / 2 + 0.5\n",
        "    img = np.moveaxis(img, 0, -1)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "# display sample from dataset \n",
        "imgs, labels = iter(trainloader).next()\n",
        "imshow(torchvision.utils.make_grid(imgs)) \n",
        "\n",
        "# notice who we converted the class idx to labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "# run this cell multiple times and notice diff images\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ship plane   cat  bird\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJK32k42gbEK",
        "colab_type": "code",
        "outputId": "36662b47-e4a0-4b68-9d54-3abdc471c1c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# divide the training dataset into the required groups Make sure they are balanced\n",
        "\n",
        "total_size = len(trainset)\n",
        "split1 = total_size // 4\n",
        "split2 = split1 * 2\n",
        "split3 = split1 * 3\n",
        "\n",
        "print(total_size, split1, split2, split3)\n",
        "\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "shadow_train_idx = indices[:split1]\n",
        "shadow_out_idx = indices[split1:split2]\n",
        "\n",
        "# two groups to train the Target (in and out)\n",
        "target_train_idx = indices[split2:split3]\n",
        "target_out_idx = indices[split3:]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 12500 25000 37500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4wJ_0lkhp76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx)\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx)\n",
        "\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx)\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx)\n",
        "\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj9LuQJNuCXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a CNN\n",
        "# Input shape (3, 32, 32) \n",
        "# architecture: simple. 2 conv and 2 Max pool, followed by 2 fc (120, 84) output of fc is 10 cuz we have 10 classes!\n",
        "\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5) # input channels = 3, output channels=6, kernel_size =5 \n",
        "        self.pool = nn.MaxPool2d(2, 2)  # kernel size = 2, stride = 2\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5) \n",
        "        \n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER_B4V8YjKyU",
        "colab_type": "code",
        "outputId": "7c60bd4a-d326-41e7-ac32-a1ddba4ff2d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "# initalize a target model and train it\n",
        "\n",
        "target_model = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(target_model.parameters(), lr=0.01)\n",
        "\n",
        "# let the magic begin\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for i, data in enumerate(target_train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = target_model(inputs) # make a prediction: forward prop\n",
        "        \n",
        "        loss = criterion(outputs, labels) # calculate the loss\n",
        "        \n",
        "        loss.backward() # calculate gradients\n",
        "        \n",
        "        optimizer.step() # updaate weights in backprop\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "       \n",
        "        \n",
        "        if i % 50 == 49:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 50))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training the Target model')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    50] loss: 2.304\n",
            "[1,   100] loss: 2.305\n",
            "[1,   150] loss: 2.305\n",
            "[2,    50] loss: 2.302\n",
            "[2,   100] loss: 2.302\n",
            "[2,   150] loss: 2.303\n",
            "Finished Training the Target model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpY8ktdskRQN",
        "colab_type": "code",
        "outputId": "ae411abf-16b5-425b-f845-994d56ec33f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the accuracy of the Target Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in target_out_loader:\n",
        "        images, labels = data\n",
        "        outputs = target_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 9 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEClKFqikmUl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha_VqRVVkoCm",
        "colab_type": "code",
        "outputId": "79a312e9-fdee-48a4-89ea-6f94ea7a8e84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "# initalize a Shadow Model and Train it\n",
        "# for the first ICP trail use the same CNN architecture and hyperparameters\n",
        "\n",
        "shadow_model = Net()\n",
        "shadow_criterion = nn.CrossEntropyLoss()\n",
        "shadow_optimizer = optim.SGD(shadow_model.parameters(), lr=0.0001)\n",
        "\n",
        "# let the magic begin\n",
        "for epoch in range(20):  # loop over the dataset multiple times\n",
        "\n",
        "    shadow_running_loss = 0.0\n",
        "    \n",
        "    for i, data in enumerate(shadow_train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = shadow_model(inputs) # make a prediction: forward prop\n",
        "        \n",
        "        shadow_loss = shadow_criterion(outputs, labels) # calculate the loss\n",
        "        \n",
        "        shadow_loss.backward() # calculate gradients\n",
        "        \n",
        "        shadow_optimizer.step() # updaate weights in backprop\n",
        "\n",
        "        # print statistics\n",
        "        shadow_running_loss += shadow_loss.item()\n",
        "       \n",
        "    print(shadow_running_loss / len(shadow_train_loader))\n",
        "    shadow_running_loss = 0.0\n",
        "\n",
        "print('Finished Training the Shadow model')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.303216498725268\n",
            "2.297934685434614\n",
            "2.2851757638308468\n",
            "2.223008378427856\n",
            "2.1082073778522257\n",
            "2.0052621364593506\n",
            "1.9085368818166304\n",
            "1.789306296377766\n",
            "1.7210499078643566\n",
            "1.6675348002083448\n",
            "1.6263141327974748\n",
            "1.6064707831460603\n",
            "1.5834928203602225\n",
            "1.5653910205072286\n",
            "1.55091715953788\n",
            "1.5268696382337688\n",
            "1.5059006560821921\n",
            "1.4840659523496822\n",
            "1.4504571873314527\n",
            "1.4467934452149334\n",
            "Finished Training the Shadow model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0kP_-62ljFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# freeze the Shadow model \n",
        "shadow_model.eval()\n",
        "shadow_output = []\n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "with torch.no_grad():\n",
        "  for i, data in enumerate(shadow_train_loader, 0) :\n",
        "    inputs, labels = data\n",
        "    output = shadow_model(inputs)\n",
        "    for outputs_item in output:\n",
        "      shadow_output.append([outputs_item,1])\n",
        "  for i, data in enumerate(shadow_out_loader, 0) :\n",
        "    inputs, labels = data\n",
        "    output = shadow_model(inputs)\n",
        "    for outputs_item in output:\n",
        "      shadow_output.append([outputs_item,0])\n",
        "# create a new dataset of the shape [predictions(shadow_in), 1], [predicitons(shadow_out), 1] and zip them together\n",
        "shadoww = torch.utils.data.DataLoader(shadow_output, batch_size=4,shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ymKnj7QpdDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "1c8e8770-c903-4af4-c677-7b15b66a4b46"
      },
      "source": [
        "# create the Attack Model\n",
        "# A NN binary classifier {0, 1}\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(10, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 2)\n",
        "\n",
        "        # Dropout module with 0.2 drop probability\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # make sure input tensor is flattened\n",
        "        x = x.view(x.shape[0], -1)\n",
        "\n",
        "        # Now with dropout\n",
        "        x = self.dropout(F.sigmoid(self.fc1(x)))\n",
        "        x = self.dropout(F.sigmoid(self.fc2(x)))\n",
        "        x = self.dropout(F.sigmoid(self.fc3(x)))\n",
        "\n",
        "        # output so no dropout here\n",
        "        x = F.log_softmax(self.fc4(x), dim=1)\n",
        "\n",
        "        return x\n",
        "      \n",
        "# the input is a propability distribution and the output is 0 (out) or 1 (in in the training data)\n",
        "attack_model = Classifier()\n",
        "criterion = nn.NLLLoss()\n",
        "attack_optimizer = optim.SGD(attack_model.parameters(), lr=0.001)\n",
        "# let the magic begin\n",
        "for epoch in range(20):  # loop over the dataset multiple times\n",
        "  attack_running_loss = 0.0\n",
        "  for data in shadoww:\n",
        "    # get the inputs; data is a list of [inputs, labels]\n",
        "    inputs, labels = data\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "    # forward + backward + optimize\n",
        "    outputs = attack_model(inputs) # make a prediction: forward prop\n",
        "    attack_loss = criterion(outputs,labels) # calculate the loss\n",
        "    attack_loss.backward() # calculate gradients\n",
        "    attack_optimizer.step() # updaate weights in backprop\n",
        "    attack_running_loss += attack_loss.item()\n",
        "  print(attack_running_loss / len(shadoww))   \n",
        "  attack_running_loss = 0.0\n",
        "\n",
        "print('Finished Training the attack model')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9789749527704715\n",
            "1.3281725533698499\n",
            "0.9494186792999506\n",
            "1.071367412906885\n",
            "1.3087977059513332\n",
            "1.4482177091009543\n",
            "1.5079901450260356\n",
            "1.6394109229839966\n",
            "2.119437985195685\n",
            "2.180929435651591\n",
            "1.2304893439815938\n",
            "1.067216466217041\n",
            "0.9036577116855979\n",
            "1.7373417623674776\n",
            "2.590783707565558\n",
            "2.264846880475171\n",
            "2.952036891312986\n",
            "4.842065497534474\n",
            "4.109669561075697\n",
            "4.567245050781882\n",
            "Finished Training the attack model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J1B1OhMp6er",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "e03d222f-a204-4e74-88aa-85d4b3fbb07e"
      },
      "source": [
        "# calculate the recall and precision of your attack network using the Target_out and Target_in datasets\n",
        "# to do so, take a random numer of datapoints, run them throw the target model,\n",
        "# and then input the output of the target model to your attack network \n",
        "# you already know the target_in and target_out samples, so use that info to evaluare the attack model\n",
        "\n",
        "accuracy = 0\n",
        "equals = 0\n",
        "with torch.no_grad():\n",
        "  attack_model.eval()\n",
        "  for data in target_out_loader:\n",
        "    inputs, labels = data\n",
        "    outputs = target_model(inputs)\n",
        "    ans = attack_model(outputs)\n",
        "    for i in ans :\n",
        "      equals = 0\n",
        "      if i[0] > i[1] :\n",
        "        equals += 1\n",
        "    accuracy += equals / len(ans)\n",
        "  for data in target_train_loader:\n",
        "    inputs, labels = data\n",
        "    outputs = target_model(inputs)\n",
        "    ans = attack_model(outputs)\n",
        "    for i in ans :\n",
        "      equals = 0\n",
        "      if i[0] < i[1] :\n",
        "        equals += 1\n",
        "    accuracy += equals / len(ans)\n",
        "  accuracy = accuracy / (len(target_out_loader)+len(target_train_loader)) * 100\n",
        "print(accuracy)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7.900191326530613\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMsyCgziqeaa",
        "colab_type": "text"
      },
      "source": [
        "Great! At this point, you must have created a succesfful attack model that can detect whether a datapoint was used in training a target mode or not. \n",
        "* A successful attack model is one with a precision/recall higher than 85% -- you are using same architecture and are aware of the data classes\n",
        "\n",
        " \n",
        " Can you suggest any defense mechanism? If yes, Apply them to your solution and re-evaluate your attack model. How did your defense mecanism affect the accuracy of the target model? How did it affect the recall and precision of the Attack model?"
      ]
    }
  ]
}